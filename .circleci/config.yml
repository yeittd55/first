# Python CircleCI 2.1 configuration file
#
# Check https://circleci.com/docs/2.0/language-python/ for more details
#
version: 2.1
orbs:
  slack: circleci/slack@3.4.2
commands:
  update-submodules:
    steps:
      - run:
          # `git submodule update --remote` checks out the submodule repo's
          # HEAD (as opposed to whatever commit is specified in the
          # submodule). We want to ensure we're always testing against
          # the most recent commit in our component-template repo.
          name: Update submodules
          command: |
            git submodule init
            git submodule update --remote

  pre-cache:
    steps:
      - run: &get_make_checksum
          name: Get 'make' checksum
          command: |
            echo 'export SUDO="sudo"' >> $BASH_ENV
            cp -f /usr/bin/make make.bin
            md5sum make.bin > ~/make.md5

      - run: &get_dot_checksum
          name: Get 'dot' checksum
          command: |
            if [ -f /usr/bin/dot ] ; then
              cp -f /usr/bin/dot dot.bin
              md5sum dot.bin > ~/dot.md5
            else
              touch dot.bin
              md5sum dot.bin > ~/dot.md5
              rm -f dot.bin
            fi

      - run: &create_python_cache_key
          # Combine hashes of the Python interpreter, Pipfile, and today's
          # date into a file whose checksum will key the Python virtualenv.
          #
          # This means that our virtualenv cache will expire each day. We do
          # this because we are not using a lockfile to pin dependencies -
          # instead, each time CircleCI rebuilds the virtualenv, it uses the
          # latest compatible version of each dependency (which mirrors what
          # happens when a user installs Streamlit locally). So we expire our
          # virtualenv cache daily to prevent it from getting far out of sync
          # with what a fresh Streamlit installation would look like.
          name: Create Python environment cache key
          command: |
            md5sum $(which python) > ~/python_cache_key.md5
            md5sum lib/Pipfile >> ~/python_cache_key.md5
            md5sum lib/test-requirements.txt >> ~/python_cache_key.md5
            date +%F >> ~/python_cache_key.md5

      - run: &create_yarn_cache_key
          name: Create Yarn cache key
          command: |
            md5sum frontend/yarn.lock > ~/yarn.lock.md5

  restore-from-cache:
    steps:
      - restore_cache: &restore_virtualenv
          name: Restore virtualenv from cache
          keys:
            - v13-python-venv-{{ checksum "~/python_cache_key.md5" }}

      - restore_cache: &restore_nvm
          name: Restore nvm and node_modules from cache
          keys:
            - v13-nvm_node_modules-{{ checksum "~/yarn.lock.md5" }}

      - restore_cache: &restore_make
          name: Restore make from cache
          keys:
            - v13_make.bin-{{ checksum "~/make.md5" }}

      - restore_cache: &restore_dot
          name: Restore dot from cache
          keys:
            - v13_dot.bin-{{ checksum "~/dot.md5" }}

  pre-make:
    steps:
      - run: &install_make
          name: Install make
          command: |
            if [ -s make.bin ] ; then
              echo "make.bin exists; not installing"
            else
              echo "/usr/bin/make doesn't exist; installing"
              apt-get update -y
              apt-get install -y make
              cp -f /usr/bin/make make.bin
            fi
            ${SUDO} cp -f make.bin /usr/bin/make

      - run: &install_dot
          name: Install dot
          command: |
            if [ -s dot.bin ] ; then
              echo "dot.bin exists and is non zero"
            else
              echo "/usr/bin/dot doesn't exist, installing"
              ${SUDO} apt-get update -y
              ${SUDO} apt-get install -y graphviz
              cp -f /usr/bin/dot dot.bin
            fi
            ${SUDO} cp -f dot.bin /usr/bin/dot

  make-init:
    steps:
      - run: &install_nodejs
          name: Install NVM, Node.js, and Yarn
          command: |
            if [ ! -d ~/.nvm ] ; then
              # install nodejs via nvm
              curl -o- https://raw.githubusercontent.com/creationix/nvm/v0.35.2/install.sh | bash
              source "$HOME/.nvm/nvm.sh"
              nvm install --lts=fermium
              # install yarn
              npm install -g yarn
            fi
            if [ ! -d frontend/node_modules ] ; then
              source "$HOME/.nvm/nvm.sh"
            fi
            make react-init
            echo 'export NVM_DIR="$HOME/.nvm"' >> $BASH_ENV
            echo 'source "$NVM_DIR/nvm.sh"' >> $BASH_ENV

      - run:
          name: Install pyodbc dependencies
          command: |
            ${SUDO} apt-get install -y unixodbc-dev

      - run:
          name: Install graphviz dependencies
          command: |
            ${SUDO} apt-get install -y libgvc6

      - run: &activate_virtualenv
          name: Create virtualenv
          command: |
            echo 'Checking for virtualenv'
            if [ ! -d venv ] ; then
              # The virtualenv was NOT restored from cache. Create a new one.
              python -m venv venv
              source venv/bin/activate
              pip install --upgrade pip
              make setup
              make pipenv-install
              deactivate
            else
              # The virtualenv WAS restored from cache. Don't create a new one.
              echo 'Virtualenv already exists, not creating'
            fi

            # Add 'activate venv' to $BASH_ENV. This means that our venv will be active
            # for the remainder of the job ($BASH_ENV is evaluated at each step).
            echo 'source venv/bin/activate' >> $BASH_ENV

      - run: &generate_protobufs
          name: Generate protobufs
          command: |
            # install protobuf v3
            ${SUDO} apt-get update -y
            ${SUDO} apt-get install -y gnupg
            echo "deb http://ppa.launchpad.net/maarten-fonville/protobuf/ubuntu trusty main" | ${SUDO} tee /etc/apt/sources.list.d/protobuf.list
            ${SUDO} apt-key adv --keyserver keyserver.ubuntu.com --recv-keys 4DEA8909DC6A13A3
            ${SUDO} apt-get update -y
            ${SUDO} apt-get install -y protobuf-compiler

            # Generate protobufs
            make protobuf

workflows:
  circleci:
    jobs:
      - python-3-6: # Oldest supported Python minor version.
          filters:
            tags:
              only: /^([0-9]+\.){3}dev[0-9]+/ # 0.56.1.dev20201129
      - python-3-8: # Latest supported Python minor version.
          filters:
            tags:
              only: /^([0-9]+\.){3}dev[0-9]+/
      - cypress: # Non flaky Cypress tests
          filters:
            tags:
              only: /^([0-9]+\.){3}dev[0-9]+/
      - pr-preview: # Make a preview branch for each PR
          filters:
            tags:
              only: /^([0-9]+\.){3}dev[0-9]+/
      - nightly-release:
          requires:
            - python-3-6
            - python-3-8
            - cypress
          filters:
            tags:
              only: /^([0-9]+\.){3}dev[0-9]+/
            branches:
              ignore: /.*/
      # Uncomment to get a button that runs flaky tests on CircleCI:
      # - cypress-flaky-approval:
      #     type: approval
      #     requires:
      #       - python-3-8
      # - cypress: # Flaky Cypress tests
      #     name: cypress-flaky
      #     flaky: true
      #     requires:
      #       - cypress-flaky-approval

  create-nightly-tag:
    triggers:
      - schedule:
          # Run job at 10.30pm PST or 11.30pm PDT
          cron: "30 6 * * *"
          filters:
            branches:
              only:
                - develop
    jobs:
      - create-tag

jobs:
  python-3-8: &job-template
    docker:
      - image: circleci/python:3.8.1

    working_directory: ~/repo

    steps:
      - checkout:
          name: Checkout Streamlit code

      - update-submodules

      #################################################################
      # Pre Cache Steps
      #################################################################
      - pre-cache

      #################################################################
      # Restore from cache
      #################################################################
      - restore-from-cache

      #################################################################
      # Pre Make commands
      #################################################################
      - pre-make

      - save_cache:
          name: Save make to cache
          key: v13_make.bin-{{ checksum "~/make.md5" }}
          paths:
            - make.bin

      - save_cache:
          name: Save dot to cache
          key: v13_dot.bin-{{ checksum "~/dot.md5" }}
          paths:
            - dot.bin

      #################################################################
      # Run 'make init'
      #################################################################
      - make-init

      - run: &make_develop
          name: Run make develop
          command: |
            make develop

      #################################################################
      # Run linters
      #################################################################
      - run:
          name: Run linters
          command: |
            make jslint
            make pylint

      - store_test_results:
          path: frontend/test-reports
          when: always

      #################################################################
      # Run mypy. (Only executed in one job.)
      #################################################################
      - run:
          name: Run mypy
          command: |
            if [ "${CIRCLE_JOB}" != "python-3-8" ] ; then
              echo "Mypy is only run in python-3.8 job"
            else
              scripts/mypy --report
            fi

      - store_test_results:
          path: lib/test-reports
          when: always

      #################################################################
      # Run make pycoverage
      #################################################################
      - run:
          name: Run python tests
          command: |
            make pycoverage

      - store_test_results:
          path: lib/test-reports
          when: always

      #################################################################
      # Run integration tests
      #################################################################
      - run:
          name: Run integration tests
          command: |
            make integration-tests

      #################################################################
      # Run CLI smoke tests
      #################################################################
      - run:
          name: CLI smoke tests
          command: |
            make cli-smoke-tests

      #################################################################
      # Run frontend tests. (Only executed in one job.)
      #################################################################
      - run:
          name: Run frontend tests
          command: |
            if [ "${CIRCLE_JOB}" != "python-3-8" ] ; then
              echo "Frontend tests are only run in python-3.8 job"
            else
              make jstest
            fi

      #################################################################
      # Save cache for python virtualenv and node_modules.
      #################################################################
      - save_cache:
          name: Save virtualenv to cache
          key: v13-python-venv-{{ checksum "~/python_cache_key.md5" }}
          paths:
            - venv

      - save_cache:
          name: Save nvm and node_modules to cache
          key: v13-nvm_node_modules-{{ checksum "~/yarn.lock.md5" }}
          paths:
            - ~/.nvm
            - ~/.cache

      - when:
          condition: <<pipeline.git.tag>>
          steps:
            - slack/status:
                fail_only: true
                failure_message: ":blobonfire: Nightly job failed on unit tests"

  # The following inherits from python-3-8. In a few cases, steps are skipped
  # based on the name of the current job (see, e.g., "Run frontend tests").
  python-3-6:
    <<: *job-template
    docker:
      - image: circleci/python:3.6.5

  create-tag:
    docker:
      - image: circleci/python:3.8.1

    working_directory: ~/repo

    steps:
      - checkout:
          name: Checkout Streamlit code

      - update-submodules

      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run:
          <<: *make_develop

      - run:
          name: Create tag
          # TODO move git commands into script
          command: |
            git config user.email "jonathan@streamlit.io"
            git config user.name "CircleCI"

            TAG="$(./scripts/pypi_nightly_create_tag.py)"

            ./scripts/update_version.py $TAG
            ./scripts/update_name.py streamlit-nightly

            git add lib/setup.py
            git add docs/troubleshooting/sanity-checks.md
            git add frontend/package.json

            git add lib/streamlit/__init__.py
            git add lib/streamlit/version.py

            git commit -m "Update version and project name in files"

            git tag -a $TAG -m "Streamlit nightly $TAG"
            git push origin $TAG

      - slack/status:
          fail_only: true
          failure_message: ":blobonfire: Nightly job failed to create a tag"

  nightly-release:
    docker:
      - image: circleci/python:3.8.1

    resource_class: large

    working_directory: ~/repo

    steps:
      - checkout:
          name: Checkout Streamlit code

      - update-submodules

      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run:
          name: verify git tag vs. version
          command: |
            cd lib
            python setup.py verify

      # Password added to circleci environment
      # https://ui.circleci.com/settings/project/github/streamlit/streamlit/environment-variables
      - run:
          name: init .pypirc
          command: |
            cd lib
            echo -e "[pypi]" >> ~/.pypirc
            echo -e "username = streamlit" >> ~/.pypirc
            echo -e "password = $PYPI_PASSWORD" >> ~/.pypirc

      - run:
          name: create packages
          no_output_timeout: 2h
          command: |
            ${SUDO} apt-get install rsync
            make package

      - run:
          name: upload to pypi
          command: |
            make distribute

      - slack/status:
          fail_only: true
          failure_message: ":blobonfire: Nightly job failed to release"

  pr-preview:
    docker:
      - image: circleci/python:3.8.1

    resource_class: large

    working_directory: ~/repo

    steps:
      - add_ssh_keys:
          name: Add the read/write Github deploy key
          fingerprints:
            - "06:66:05:ea:ba:10:ec:b4:93:06:ab:62:7c:20:33:f0"

      - checkout:
          name: Checkout Streamlit code

      - update-submodules
      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run:
          name: Create wheel file
          no_output_timeout: 2h
          command: |
            ${SUDO} apt-get install rsync
            make package

      - run:
          name: Set PREVIEW_BRANCH envvar
          command: |
            echo "export PREVIEW_BRANCH=$(
              if [[ -n "${CIRCLE_PR_NUMBER}" ]]
              then
                echo "pr-${CIRCLE_PR_NUMBER}"
              elif [[ -n "${CIRCLE_BRANCH}" ]]
              then
                echo "${CIRCLE_BRANCH}-preview"
              elif [[ -n "${CIRCLE_TAG}" ]]
              then
                echo "tag-${CIRCLE_TAG}"
              else
                echo "main-preview"
              fi
            )" >> $BASH_ENV

      - run:
          name: Upload wheel to S3
          command: |
            ${SUDO} apt-get install -y awscli
            aws configure set aws_access_key_id ${CORE_PREVIEWS_S3_KEY_ID}
            aws configure set aws_secret_access_key ${CORE_PREVIEWS_S3_SECRET_KEY}

            cd lib/dist
            export WHEELFILE="$(ls -t *.whl | head -n 1)"

            aws s3 cp ${WHEELFILE} s3://core-previews/${PREVIEW_BRANCH}/ --acl public-read
            cd ../..

            echo -e "https://core-previews.s3-us-west-2.amazonaws.com/${PREVIEW_BRANCH}/${WHEELFILE}" >> S3_URL

      - run:
          name: Setup preview repo
          command: |
            git config --global user.email "austin@streamlit.io"
            git config --global user.name "CircleCI"
            git clone git@github.com:streamlit/core-previews.git

            cd core-previews
            git branch -D ${PREVIEW_BRANCH} &>/dev/null || true
            git checkout -b ${PREVIEW_BRANCH}

            cat ../S3_URL >> requirements.txt

            git add .
            git commit -m "Prepare core preview: ${PREVIEW_BRANCH}"
            git push -f origin ${PREVIEW_BRANCH}

      - run:
          name: Ready to deploy!
          command: |
            echo -e "https://share.streamlit.io/deploy?repository=streamlit/core-previews&branch=pr-${CIRCLE_PR_NUMBER}&mainModule=streamlit_app.py"

  cypress:
    docker:
      - image: circleci/python:3.7.4-stretch

    resource_class: xlarge

    working_directory: ~/repo

    parameters:
      flaky:
        description: "Run flaky tests"
        default: false
        type: boolean

    steps:
      - checkout:
          name: Checkout Streamlit code

      - update-submodules

      - pre-cache
      - restore-from-cache
      - pre-make
      - make-init

      - run:
          <<: *make_develop

      - run:
          name: Install Cypress dependencies
          command: |
            ${SUDO} apt-get install -y xvfb libgtk2.0-0 libnotify-dev libgconf-2-4 libnss3 libxss1 libasound2 jq curl

      - run:
          name: Init config
          command: |
            mkdir ~/.streamlit
            MAPBOX_TOKEN=$(curl -sS https://data.streamlit.io/tokens.json | jq -r '.["mapbox-localhost"]')
            echo '[mapbox]' >  ~/.streamlit/config.toml
            echo 'token = "'$MAPBOX_TOKEN'"' >> ~/.streamlit/config.toml

      - run:
          name: Init credentials
          command: |
            echo '[general]' >  ~/.streamlit/credentials.toml
            echo 'email = "test@streamlit.io"' >> ~/.streamlit/credentials.toml

      - when:
          condition: << parameters.flaky >>
          steps:
            - run:
                name: Cypress
                command: |
                  cd frontend
                  yarn run cy:serve-and-run-all-flaky

      - unless:
          condition: << parameters.flaky >>
          steps:
            - run:
                name: Cypress
                command: |
                  cd frontend
                  yarn run cy:serve-and-run-all

      - store_test_results: &store_results
          path: frontend/test-reports
          when: always

      - store_artifacts: &store_report
          path: frontend/mochawesome-report

      - store_artifacts: &store_videos
          path: frontend/cypress/videos

      - store_artifacts: &store_snapshots
          path: frontend/cypress/snapshots

      - when:
          condition: <<pipeline.git.tag>>
          steps:
            - slack/status:
                fail_only: true
                failure_message: ":blobonfire: Nightly job failed on E2E tests"
